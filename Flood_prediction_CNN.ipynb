{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82zGJRZ5hDxx"
   },
   "outputs": [],
   "source": [
    "#!jupyter nbconvert --to html Machine-Learning-Challenge-CloudtoStreet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJUW1KQa6esb"
   },
   "outputs": [],
   "source": [
    "#!kill -9 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6669,
     "status": "ok",
     "timestamp": 1623126561964,
     "user": {
      "displayName": "Zexuan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbxjoZOFhwsP4feWSEc804gz-Y7lJZR1qxXzymNg=s64",
      "userId": "04269007640645982603"
     },
     "user_tz": 420
    },
    "id": "ymPnuiJNFt5h",
    "outputId": "9c3398a2-aa32-47bd-b500-0113dd4a9843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasterio\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/78/c69f7457b7dad6163abde2772abd4c8c0c6498d2ab9fd3f3b0eb73b40951/rasterio-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (19.3MB)\n",
      "\u001b[K     |████████████████████████████████| 19.3MB 1.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2020.12.5)\n",
      "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
      "Collecting click-plugins\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.0.0)\n",
      "Collecting snuggs>=1.4.1\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/0e/d27d6e806d6c0d1a2cfdc5d1f088e42339a0a54a09c3343f7f81ec8947ea/snuggs-1.4.7-py3-none-any.whl\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.2.0)\n",
      "Collecting affine\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/a6/1a39a1ede71210e3ddaf623982b06ecfc5c5c03741ae659073159184cd3e/affine-2.3.0-py2.py3-none-any.whl\n",
      "Collecting cligj>=0.5\n",
      "  Downloading https://files.pythonhosted.org/packages/73/86/43fa9f15c5b9fb6e82620428827cd3c284aa933431405d1bcf5231ae3d3e/cligj-0.7.2-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.19.5)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (2.4.7)\n",
      "Installing collected packages: click-plugins, snuggs, affine, cligj, rasterio\n",
      "Successfully installed affine-2.3.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.2.4 snuggs-1.4.7\n"
     ]
    }
   ],
   "source": [
    "pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 13778,
     "status": "error",
     "timestamp": 1623117075630,
     "user": {
      "displayName": "Zexuan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbxjoZOFhwsP4feWSEc804gz-Y7lJZR1qxXzymNg=s64",
      "userId": "04269007640645982603"
     },
     "user_tz": 420
    },
    "id": "tmhtwTPT5T76",
    "outputId": "653fd944-e9f5-420f-be6e-c28c1de870e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gputil\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
      "Building wheels for collected packages: gputil\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gputil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=0316f8942304fc3bdc916a75aa3107efecce02acc05265373eea4bc8b5d6281b\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
      "Successfully built gputil\n",
      "Installing collected packages: gputil\n",
      "Successfully installed gputil-1.4.0\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6fccab01afdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mGPUs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetGPUs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# XXX: only one GPU on Colab and isn’t guaranteed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPUs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprintm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isn’t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    "  process = psutil.Process(os.getpid())\n",
    "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23375,
     "status": "ok",
     "timestamp": 1623126585541,
     "user": {
      "displayName": "Zexuan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbxjoZOFhwsP4feWSEc804gz-Y7lJZR1qxXzymNg=s64",
      "userId": "04269007640645982603"
     },
     "user_tz": 420
    },
    "id": "COaadKNs7dcy",
    "outputId": "9e6d22d6-58d6-4812-a2d6-c9b83835538f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1623126585542,
     "user": {
      "displayName": "Zexuan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbxjoZOFhwsP4feWSEc804gz-Y7lJZR1qxXzymNg=s64",
      "userId": "04269007640645982603"
     },
     "user_tz": 420
    },
    "id": "5y7JTUN0hDx1"
   },
   "outputs": [],
   "source": [
    "# these are the packages we need for exploration, please install them e.g. in colab you need !pip install rasterio\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.collections import PatchCollection\n",
    "from shapely.geometry import Polygon\n",
    "from rasterio.features import shapes\n",
    "from descartes import PolygonPatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4631,
     "status": "ok",
     "timestamp": 1623126590168,
     "user": {
      "displayName": "Zexuan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbxjoZOFhwsP4feWSEc804gz-Y7lJZR1qxXzymNg=s64",
      "userId": "04269007640645982603"
     },
     "user_tz": 420
    },
    "id": "AJfTCHxr5fZ0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "import cv2\n",
    "from torch.utils.data import Dataset,random_split\n",
    "import random\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1249,
     "status": "ok",
     "timestamp": 1623126591413,
     "user": {
      "displayName": "Zexuan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbxjoZOFhwsP4feWSEc804gz-Y7lJZR1qxXzymNg=s64",
      "userId": "04269007640645982603"
     },
     "user_tz": 420
    },
    "id": "lH6qK_Dq5prH"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/CloudtoStreet/')\n",
    "from models.unet_parts import *\n",
    "from models.unet_model import UNet\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opvnv2xqhDx1"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XIy_JwNhDx1"
   },
   "source": [
    "We will use our [Sen1Floods11](https://github.com/cloudtostreet/Sen1Floods11) dataset. We will create a local folder `c2s_data/v1.1/data/flood_events/HandLabeled` and download the handlabeled training data (Sentinel-1 512x512 chips, mask labels) there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtyIDbfRhDx1"
   },
   "outputs": [],
   "source": [
    "#os.makedirs(\"/content/drive/My Drive/c2s_data/v1.1/data/flood_events/HandLabeled\", exist_ok=True)\n",
    "\n",
    "#!pip install gsutil\n",
    "##!gsutil -m rsync -r gs://sen1floods11/v1.1/data/flood_events/HandLabeled c2s_data/v1.1/data/flood_events/HandLabeled\n",
    "#!gsutil -m rsync -r gs://sen1floods11/v1.1/data/flood_events/HandLabeled \"/content/drive/My Drive/c2s_data/v1.1/data/flood_events/HandLabeled\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhNJVPBVhDx2"
   },
   "source": [
    "There are some faulty labels we will remove here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZ8QodfVhDx2"
   },
   "outputs": [],
   "source": [
    "def remove_faulty(img_folder=\"/content/drive/My Drive/c2s_data/v1.1/data/flood_events/HandLabeled/S1Hand\", \n",
    "                  label_folder=\"/content/drive/My Drive/c2s_data/v1.1/data/flood_events/HandLabeled/LabelHand\"):\n",
    "    for uid in [\n",
    "        'Ghana_141910',\n",
    "        'Ghana_866994',\n",
    "        'Mekong_1111068',\n",
    "        'Pakistan_35915',\n",
    "        'Pakistan_94095',\n",
    "        'Paraguay_34417',\n",
    "        'Paraguay_581976',\n",
    "        'Spain_6095801'\n",
    "    ]:\n",
    "        \n",
    "        faulty_img = f\"{img_folder}/{uid}_S1Hand.tif\"\n",
    "        if os.path.exists(faulty_img):\n",
    "            print('removing: ', faulty_img)\n",
    "            os.remove(faulty_img)\n",
    "\n",
    "        faulty_label = f\"{label_folder}/{uid}_LabelHand.tif\"\n",
    "        if os.path.exists(faulty_label):\n",
    "            print('removing: ', faulty_label)\n",
    "            os.remove(faulty_label)\n",
    "\n",
    "#remove_faulty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd7_bpB7hDx2"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnlBgDirhDx3"
   },
   "outputs": [],
   "source": [
    "def get_patchcollection_from_label(label, label_value=1, alpha=1, color=\"cyan\"):\n",
    "    \"\"\"Turns a (H,W) mask into a PatchCollection of polygons\"\"\"\n",
    "    polygons, colors = [], []\n",
    "    for geom in shapes((label == label_value).astype(np.uint8), mask=(label == label_value).astype(np.uint8),\n",
    "                       connectivity=4):\n",
    "        poly = Polygon(geom[0]['coordinates'][0], holes=geom[0]['coordinates'][1:])\n",
    "        polygons.append(PolygonPatch(poly.buffer(0)))\n",
    "        colors.append(color)\n",
    "    return PatchCollection(polygons, facecolor=colors, linewidths=0, alpha=alpha)\n",
    "\n",
    "def visualize_s1_img(path):\n",
    "    \"\"\"Opens a Sentinel 1 image and returns a scaled RFCC false color composite image for visualization.\"\"\"\n",
    "    s1_img = tifffile.imread(path)\n",
    "    if s1_img.shape[0] < 15: s1_img = np.transpose(s1_img, (1, 2, 0))\n",
    "    if s1_img.shape[-1] == 3: s1_img = s1_img[:, :, :2]\n",
    "    img = np.zeros((s1_img.shape[0], s1_img.shape[1], 3), dtype=np.float32)\n",
    "    img[:, :, :2] = s1_img\n",
    "    img[:, :, 2] = s1_img[:, :, 0] / s1_img[:, :, 1]\n",
    "    return scale_S1_S2_img(img)\n",
    "\n",
    "def scale_S1_S2_img(matrix):\n",
    "    \"\"\"Returns a scaled (H,W,D) image which is more easily visually inspectable. Image is linearly scaled between\n",
    "    min and max_value of by channel\"\"\"\n",
    "    w, h, d = matrix.shape\n",
    "    min_values = np.array([-23, -28, 0.2])\n",
    "    max_values = np.array([0, -5, 1])\n",
    "\n",
    "    matrix = np.reshape(matrix, [w * h, d]).astype(np.float64)\n",
    "    matrix = (matrix - min_values[None, :]) / (max_values[None, :] - min_values[None, :])\n",
    "    matrix = np.reshape(matrix, [w, h, d])\n",
    "\n",
    "    matrix = matrix.clip(0, 1)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MM5WpVGKhDx3"
   },
   "source": [
    "# Part 1: Practical Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vp3cMP6LhDx3"
   },
   "source": [
    "## Exploration and Splitting\n",
    "\n",
    "In the folder \"S1Hand\" we have 438 512x512 Sentinel-1 images from 11 countries. The folder \"LabelHand\" contains the water/no data masks for these images. \n",
    "\n",
    "Our goal is to have a model that achieves high mean Intersection over Union over all countries. \n",
    "\n",
    "__Todo__\n",
    "- Look at the images with the code that is given. Re-run it to see different random examples from the dataset.\n",
    "- Explore the images and labels. Summarize your findings with relevant statistics and visualizations.\n",
    "- Split the data into useful train/validation/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htqO-qdthDx4"
   },
   "outputs": [],
   "source": [
    "# Countries we have data for\n",
    "print(set([k.split(\"/\")[-1].split(\"_\")[0] for k in glob.glob(\"/content/drive/My Drive/c2s_data/v1.1/data/flood_events/HandLabeled/S1Hand/*.tif\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lv1vwFnChDx4"
   },
   "outputs": [],
   "source": [
    "S1_imgs = sorted(glob.glob(\"/content/drive/My Drive/c2s_data/v1.1/data/flood_events/HandLabeled/S1Hand/*.tif\"))\n",
    "labels_GT = sorted(glob.glob(\"/content/drive/My Drive/c2s_data/v1.1/data/flood_events/HandLabeled/LabelHand/*.tif\"))\n",
    "print(len(S1_imgs), len(labels_GT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sMhn-vShDx4"
   },
   "source": [
    "For Visualization we are using a false color composite of the two Sentinel-1 channels and some color stretching. \n",
    "\n",
    "The label masks are 1 for water pixels (shown in cyan) and -1 for no data, e.g. clouds on the Sentinel-2 image we labeled the data on (shown in magenta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "error",
     "timestamp": 1623110807853,
     "user": {
      "displayName": "Zexuan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbxjoZOFhwsP4feWSEc804gz-Y7lJZR1qxXzymNg=s64",
      "userId": "04269007640645982603"
     },
     "user_tz": 420
    },
    "id": "iK-yIO4KhDx5",
    "outputId": "30cd742e-6173-4d99-c086-a76303a751c3",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6b7b5d27c9c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_how_many\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mrand_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS1_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS1_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_int\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'S1_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "# plot random tiles\n",
    "# S1 image on the left, and the S1 image with the hand-labels overlain on the right.\n",
    "show_how_many = 1\n",
    "color = \"cyan\"\n",
    "no_data_color = \"magenta\"\n",
    "alpha = 0.5\n",
    "for k in range(show_how_many):\n",
    "    rand_int = np.random.randint(len(S1_imgs))\n",
    "    filename = S1_imgs[rand_int].split(\"/\")[-1].split(\".\")[0] + \".png\"\n",
    "    f, axarr = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    print(filename)\n",
    "    print(tifffile.imread(S1_imgs[rand_int]).min(), tifffile.imread(S1_imgs[rand_int]).max())\n",
    "    img = visualize_s1_img(S1_imgs[rand_int])\n",
    "    print(img.min(),img.max())\n",
    "    axarr[0].imshow(img)\n",
    "    axarr[0].set_title(\"S1 image\")\n",
    "    axarr[1].imshow(img)\n",
    "    axarr[1].set_title(\"S1 image with Ground Truth\")\n",
    "         \n",
    "    label = tifffile.imread(labels_GT[rand_int])\n",
    "    p = get_patchcollection_from_label(label, alpha=alpha, color=color)\n",
    "    axarr[1].add_collection(p)\n",
    "    p = get_patchcollection_from_label(label, -1, alpha=alpha, color=no_data_color)\n",
    "    axarr[1].add_collection(p)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rs1FoGt4m-Zj"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "countries = Counter(([k.split(\"/\")[-1].split(\"_\")[0] for k in glob.glob(\"/content/drive/My Drive/c2s_data/v1.1/data/flood_events/HandLabeled/S1Hand/*.tif\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDktpQHvm-1a"
   },
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVQzdUs9tPTi"
   },
   "outputs": [],
   "source": [
    "label = tifffile.imread(labels_GT[100])\n",
    "np.unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGseSkO1KqDi"
   },
   "outputs": [],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IZ2Fuz74QKT"
   },
   "outputs": [],
   "source": [
    "img =  tifffile.imread(S1_imgs[110])\n",
    "np.unique(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8ZrKocdLODW"
   },
   "outputs": [],
   "source": [
    "np.count_nonzero(label == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCSdiZMqLQxa"
   },
   "outputs": [],
   "source": [
    "np.count_nonzero(label == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upu7kQ0iLQl_"
   },
   "outputs": [],
   "source": [
    "np.count_nonzero(label == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3FBtXwMtPJV"
   },
   "outputs": [],
   "source": [
    "#zero_count=0\n",
    "#p1_count=0\n",
    "#n1_count=0\n",
    "#for k in glob.glob(\"/content/drive/My Drive/c2s_data/v1.1/data/flood_events/HandLabeled/LabelHand/*.tif\"):\n",
    "#  array = np.array(tifffile.imread(k))\n",
    "#  p1_count += np.count_nonzero(array == 1)\n",
    "#  n1_count += np.count_nonzero(array == -1)\n",
    "#  zero_count += np.count_nonzero(array == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_BzTyWwtO9X"
   },
   "outputs": [],
   "source": [
    "#print(p1_count/(p1_count+n1_count+zero_count))\n",
    "#print(zero_count/(p1_count+n1_count+zero_count))\n",
    "#print(n1_count/(p1_count+n1_count+zero_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "wyXM-PHgKmKu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset_count 438\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n",
      "torch.Size([1, 2, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "class Sentinel_Loader(Dataset):\n",
    "\t\n",
    "  def __init__(self, data_path):\n",
    "    self.data_path = data_path\n",
    "    self.imgs_path = glob.glob(os.path.join(data_path, 'S1Hand/*.tif'))\n",
    "#    self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    image_path = self.imgs_path[index]\n",
    "    label_path = image_path.replace('S1Hand', 'LabelHand')\n",
    "\n",
    "    image = tifffile.imread(image_path)\n",
    "    label = tifffile.imread(label_path)\n",
    "    image = image.reshape(2, image.shape[1], image.shape[2])\n",
    "    label = label.reshape(label.shape[0], label.shape[1])\n",
    "    image = (image - np.nanmin(image))/(np.nanmax(image) - np.nanmin(image))\n",
    "    image[image != image] = 2\n",
    "#    print(image.min(), image.max())\n",
    "    label = np.where(label == -1, 2, label)\n",
    "    return image, label\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.imgs_path)\n",
    "\t\n",
    "if __name__ == \"__main__\":\n",
    "  sentinel_dataset = Sentinel_Loader(\"/content/drive/My Drive/c2s_data/v1.1/data/flood_events/HandLabeled/\")\n",
    "  print(\"Dataset_count\", len(sentinel_dataset))\n",
    "  train_loader = torch.utils.data.DataLoader(dataset=sentinel_dataset,\n",
    "                                               batch_size=1, \n",
    "                                               shuffle=True)\n",
    "  for image, label in train_loader:\n",
    "    print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFSpDxk06Y_1"
   },
   "outputs": [],
   "source": [
    "sentinel_dataset = Sentinel_Loader(\"/content/drive/My Drive/c2s_data/v1.1/data/flood_events/HandLabeled/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPtdofeJ6Y82"
   },
   "outputs": [],
   "source": [
    "#sentinel_dataset = Sentinel_Loader(\"/content/drive/My Drive/c2s_data/v1.1/data/flood_events/HandLabeled/\")\n",
    "#print(\"Dataset_count\", len(sentinel_dataset))\n",
    "#train_loader = torch.utils.data.DataLoader(dataset=sentinel_dataset,\n",
    "#                                               batch_size=4, \n",
    "#                                               shuffle=True)\n",
    "#for image, label in train_loader:\n",
    "#  print(image.shape)\n",
    "#  print(label.shape)\n",
    "#  print(label.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ojf4vhIx6Y4I"
   },
   "outputs": [],
   "source": [
    "def load_split_train_test(datadir, valid_size = .2, batch_size=4):\n",
    "\n",
    "    data_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "        \n",
    "    S1_imgs = sorted(glob.glob(datadir+\"S1Hand/*.tif\"))\n",
    "\n",
    "#    train_data = datasets.ImageFolder(datadir, transform=data_transforms)\n",
    "#    test_data = datasets.ImageFolder(datadir, transform=data_transforms)\n",
    "                              \n",
    "    num_train = len(S1_imgs)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = DataLoader(dataset=sentinel_dataset,\n",
    "                   sampler=train_sampler, batch_size=batch_size)\n",
    "    testloader = DataLoader(dataset=sentinel_dataset,\n",
    "                   sampler=test_sampler, batch_size=batch_size)\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IS6Yu7YC6nx6"
   },
   "outputs": [],
   "source": [
    "trainloader, testloader = load_split_train_test(\"/content/drive/My Drive/c2s_data/v1.1/data/flood_events/HandLabeled/\", .2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1623110820241,
     "user": {
      "displayName": "Zexuan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbxjoZOFhwsP4feWSEc804gz-Y7lJZR1qxXzymNg=s64",
      "userId": "04269007640645982603"
     },
     "user_tz": 420
    },
    "id": "itH1M0U_6pSs",
    "outputId": "3317ce05-bb60-42e7-c4f5-c127773c0c79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(len(trainloader))\n",
    "print(len(testloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rb6jNwuxhDx5"
   },
   "source": [
    "## Training\n",
    "\n",
    "__Todo__\n",
    "- Train a segmentation model in a deep learning framework of your choice (preferably PyTorch) using your train/val/test splits and the S1 images and masks. Validate on mean country IoU and save your best models for validation and testing.\n",
    "- Think about and implement how to treat the \"no data\" pixel values.\n",
    "\n",
    "Reminder: If you do not have a GPU at hand, you can use https://www.kaggle.com/kernels, https://colab.research.google.com/ for free GPUs or rent a cheap GPU at https://vast.ai/console/create/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1623111247802,
     "user": {
      "displayName": "Zexuan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbxjoZOFhwsP4feWSEc804gz-Y7lJZR1qxXzymNg=s64",
      "userId": "04269007640645982603"
     },
     "user_tz": 420
    },
    "id": "QnlsJxWj6sqE"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1623111251017,
     "user": {
      "displayName": "Zexuan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbxjoZOFhwsP4feWSEc804gz-Y7lJZR1qxXzymNg=s64",
      "userId": "04269007640645982603"
     },
     "user_tz": 420
    },
    "id": "wgDN1qdO6vn-",
    "outputId": "1b324147-7782-44a5-e1b3-d2f07f4d1708"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smlbFK_Y6vkD"
   },
   "outputs": [],
   "source": [
    "model = UNet(n_channels=2, n_classes=3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1623111249687,
     "user": {
      "displayName": "Zexuan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbxjoZOFhwsP4feWSEc804gz-Y7lJZR1qxXzymNg=s64",
      "userId": "04269007640645982603"
     },
     "user_tz": 420
    },
    "id": "TQq_e1Vq6vgk"
   },
   "outputs": [],
   "source": [
    "def _fast_hist(label_true, label_pred, n_class):\n",
    "#    print(label_true.shape)\n",
    "#    print(label_pred.shape)\n",
    "    mask = (label_true >= 0) & (label_true < n_class)\n",
    "    hist = np.bincount(\n",
    "        n_class * label_true[mask].astype(int) +\n",
    "        label_pred[mask].astype(int), minlength=n_class ** 2).reshape(n_class, n_class)\n",
    "    return hist\n",
    "\n",
    "def label_accuracy_score(label_trues, label_preds, n_class):\n",
    "    \"\"\"Returns accuracy score evaluation result.\n",
    "      - overall accuracy\n",
    "      - mean accuracy\n",
    "      - mean IU\n",
    "      - fwavacc\n",
    "    \"\"\"\n",
    "    hist = np.zeros((n_class, n_class))\n",
    "    for lt, lp in zip(label_trues, label_preds):\n",
    "        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)\n",
    "    acc = np.diag(hist).sum() / hist.sum()\n",
    "    acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
    "    acc_cls = np.nanmean(acc_cls)\n",
    "    iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "    mean_iu = np.nanmean(iu)\n",
    "    freq = hist.sum(axis=1) / hist.sum()\n",
    "    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n",
    "    return acc, acc_cls, mean_iu, fwavacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbw2kK8c63Zb"
   },
   "outputs": [],
   "source": [
    "def train_net(model, device, trainloader, epochs=80, lr=0.00001):\n",
    "\n",
    "  optimizer = optim.RMSprop(model.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
    "#  criterion = nn.BCEWithLogitsLoss()\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  best_loss = float('inf')\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_mean_iu = 0\n",
    "    for image, label in trainloader:\n",
    "      optimizer.zero_grad()\n",
    "      image = image.to(device=device, dtype=torch.float32)  \n",
    "      label = label.to(device=device, dtype=torch.long)\n",
    "\n",
    "      pred = model(image)\n",
    "      pred = F.log_softmax(pred, dim=1)\n",
    "      loss = criterion(pred, label)\n",
    "      train_loss += loss.item()\n",
    "      label_pred = pred.max(dim=1)[1].data.cpu().numpy()\n",
    "      label_true = label.data.cpu().numpy()\n",
    "\n",
    "      for lbt, lbp in zip(label_true, label_pred):\n",
    "        acc, _, mean_iu, _ = label_accuracy_score(lbt, lbp, 3)\n",
    "        train_acc += acc\n",
    "        train_mean_iu += mean_iu\n",
    "\n",
    "    if loss < best_loss:\n",
    "      best_loss = loss\n",
    "      torch.save(model.state_dict(), '/content/drive/My Drive/CV/best_model.pth')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "#### Evaluation\n",
    "    model = model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    eval_mean_iu = 0\n",
    "    for image, label in testloader:\n",
    "      image = image.to(device=device, dtype=torch.float32)  \n",
    "      label = label.to(device=device, dtype=torch.long)\n",
    "\n",
    "      pred = model(image)\n",
    "      pred = F.log_softmax(pred, dim=1)\n",
    "      loss = criterion(pred, label)\n",
    "      eval_loss += loss.item()\n",
    "      label_pred = pred.max(dim=1)[1].data.cpu().numpy()\n",
    "      label_true = label.data.cpu().numpy()\n",
    "\n",
    "      for lbt, lbp in zip(label_true, label_pred):\n",
    "        acc, _, mean_iu, _ = label_accuracy_score(lbt, lbp, 3)\n",
    "        eval_acc += acc\n",
    "        eval_mean_iu += mean_iu\n",
    "\n",
    "    epoch_str = ('Epoch: {}, Train Loss: {:.5f}, Train Acc: {:.5f}, Train Mean IU: {:.5f}, Valid Loss: {:.5f}, Valid Acc: {:.5f}, Valid Mean IU: {:.5f}'.format(\n",
    "              epoch, train_loss / len(trainloader), train_acc / len(trainloader), train_mean_iu / len(trainloader),\n",
    "              eval_loss / len(testloader), eval_acc / len(testloader), eval_mean_iu / len(testloader)\n",
    "              ))\n",
    "    print(epoch_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 1849,
     "status": "error",
     "timestamp": 1623110956552,
     "user": {
      "displayName": "Zexuan Xu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbxjoZOFhwsP4feWSEc804gz-Y7lJZR1qxXzymNg=s64",
      "userId": "04269007640645982603"
     },
     "user_tz": 420
    },
    "id": "sPdpMx_q65hQ",
    "outputId": "ef11f523-28be-4518-a322-5471c40293dc"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-da8c4ccacccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-5652a68d9fe8>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(model, device, trainloader, epochs, lr)\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m       \u001b[0mlabel_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mlabel_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "train_net(model, device, trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAblwgNNhDx6"
   },
   "source": [
    "## Testing/Visualization/Interpretation\n",
    "\n",
    "__Todo__\n",
    "- Test your model on the test data and visualize some predictions.\n",
    "- What strengths and weaknesses does it have? Give specific examples.\n",
    "- What would be your next steps and biggest levers to improve performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ji6jsC5ihFsz"
   },
   "outputs": [],
   "source": [
    "# plot random tiles\n",
    "# S1 image on the left, and the S1 image with the hand-labels overlain on the right.\n",
    "show_how_many = 1\n",
    "color = \"cyan\"\n",
    "no_data_color = \"magenta\"\n",
    "alpha = 0.5\n",
    "for k in range(show_how_many):\n",
    "    rand_int = np.random.randint(len(S1_imgs))\n",
    "    filename = S1_imgs[rand_int].split(\"/\")[-1].split(\".\")[0] + \".png\"\n",
    "    f, axarr = plt.subplots(1, 3, figsize=(20, 10))\n",
    "    print(filename)\n",
    " #   print(tifffile.imread(S1_imgs[rand_int]).min(), tifffile.imread(S1_imgs[rand_int]).max())\n",
    "    img = visualize_s1_img(S1_imgs[rand_int])\n",
    "    axarr[0].imshow(img)\n",
    "    axarr[0].set_title(\"S1 image\")\n",
    "    axarr[1].imshow(img)\n",
    "    axarr[1].set_title(\"S1 image with Ground Truth\")\n",
    "    axarr[2].imshow(img)\n",
    "    axarr[2].set_title(\"S1 image with Prediction\")\n",
    "\n",
    "    label = tifffile.imread(labels_GT[rand_int])\n",
    "    p = get_patchcollection_from_label(label, alpha=alpha, color=color)\n",
    "    axarr[1].add_collection(p)\n",
    "    p = get_patchcollection_from_label(label, -1, alpha=alpha, color=no_data_color)\n",
    "    axarr[1].add_collection(p)\n",
    "    \n",
    " #   print(S1_imgs[rand_int])\n",
    "    plot_sampler = SubsetRandomSampler(rand_int)\n",
    "    plot_loader = DataLoader(dataset=sentinel_dataset, sampler=plot_sampler, batch_size=4)    \n",
    "    \n",
    "    for image, label in trainloader:\n",
    "      image = image.to(device=device, dtype=torch.float32)  \n",
    "      pred = model(image)\n",
    "      pred = F.log_softmax(pred, dim=1)\n",
    "      label_pred = pred.max(dim=1)[1].data.cpu().numpy()\n",
    "    p = get_patchcollection_from_label(label_pred, alpha=alpha, color=color)\n",
    "    axarr[2].add_collection(p)\n",
    "    p = get_patchcollection_from_label(label_pred, -1, alpha=alpha, color=no_data_color)\n",
    "    axarr[2].add_collection(p)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acmybzyKhDx6"
   },
   "source": [
    "# Part 2: Implementing a custom model for non-standard tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyhSLeK5hDx6"
   },
   "source": [
    "Now, we want to design and test our own custom model that uses a standard U-Net architecture, but has custom inputs and outputs. As a starting point you can use any open-source implementation of U-Net like from [here](https://github.com/milesial/Pytorch-UNet).\n",
    "\n",
    "__Todo: Change a standard U-Net model to work with the following non-standard inputs and outputs in a deep learning framework of your choice (preferably PyTorch).__\n",
    "\n",
    "- __inputs__: a 10m resolution SAR image (2 channels), a 20m resolution Digital Elevation Model (1 channel) and a sequence of 8 passive microwave readings (1 channel per reading) at a 160m resolution\n",
    "- __outputs__: a 10m resolution binary water segmentation mask and a 10m resolution binary cloud segmentation mask of the same height/width as the input SAR image\n",
    "- test your model with input tensors with random data in it to see if intermediate and output shapes are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBMmHPn6MDCL"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "input_sar = Variable(torch.rand(2, 512, 512))\n",
    "input_dem = Variable(torch.rand(1, 256, 256))\n",
    "input_microwave = Variable(torch.rand(8, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUHT8eCAqllj"
   },
   "outputs": [],
   "source": [
    "model = UNet(n_channels=2, n_classes=3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-DbQdGvlTa2"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from models.unet_parts import *\n",
    "from torch import nn\n",
    "\n",
    "class C1_UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(C1_UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256, bilinear)\n",
    "        self.up2 = Up(512, 128, bilinear)\n",
    "        self.up3 = Up(256, 64, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, input1, input2, input3):\n",
    "\n",
    "        m = nn.AdaptiveMaxPool2d((input1.shape[1],input1.shape[2] ))\n",
    "        print(input1.shape)\n",
    "        output2 = m(input2)\n",
    "        output3 = m(input3)\n",
    "        print(output2.shape)\n",
    "        print(output3.shape)\n",
    "        x = torch.cat((input1,output2,output3),dim=0)\n",
    "        x = x.reshape(1, self.n_channels, x.shape[1], x.shape[2])\n",
    "\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits[:,0,:,:], logits[:,1,:,:]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    net = C1_UNet(n_channels=11, n_classes=2)\n",
    "#    print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ct9MlV-oquWC"
   },
   "outputs": [],
   "source": [
    "m1 = C1_UNet(n_channels=11, n_classes=2)\n",
    "m1 = m1.to(device)\n",
    "input1 = input_sar.to(device=device, dtype=torch.float32)\n",
    "input2 = input_dem.to(device=device, dtype=torch.float32)\n",
    "input3 = input_microwave.to(device=device, dtype=torch.float32)\n",
    "output1, output2 = m1(input1, input2, input3)\n",
    "print(output1.shape, output2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-EqRZTbe4EvQ"
   },
   "outputs": [],
   "source": [
    "# SPP layers implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnhAKIW7hDx6"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Machine-Learning-Challenge-CloudtoStreet.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
